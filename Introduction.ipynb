{
 "metadata": {
  "name": "Introduction"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This document describes the computation of Urdu poetic meter, as originally implemented by A. Sean Pue."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Urdu is written from right-to-left in a script called nastaleeq, e.g. \u0646\u0633\u062a\u0639\u0644\u06cc\u0642. It's poetic meter follows similar systems in Arabic and Persian. Urdu is an Indo-Aryan language, and is essentially the same language as modern Hindi \u0939\u093f\u0928\u094d\u0926\u0940, though written in a different script and relying more on Arabic and Persian vocabulary."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Transliterated Text</h3>\n",
      "The text used in this project has actually been transliterated (rendered in a specialized Roman alphabet) in a way that captures both its orthography and its pronunciation, e.g. \u0646\u0633\u062a\u0639\u0644\u06cc\u0642 -> nasta((liiq. \n",
      "\n",
      "While Urdu is fairly phonetic, to read it requires a certain amount of knowledge about its pronunciation in addition to its written form, as vowel markings are usually omitted. For metrical analysis, the orthography remains important, and there a few cases where letters scan even though they are not usually pronounced, as in \u0634\u0631\u0648\u0639. \n",
      "\n",
      "Working on a corpus of raw Urdu text, this abstracted transliterated form could likely be generated through a lexicon lookup along with a relatively small amount of natural language processing in order to account for small shifts in pronunciation that are not reflected orthographically, e.g. word-final \u06c1 in a noun followed by a postposition as in \u062e\u0627\u0646\u06c1 \u0645\u06cc\u06ba."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Urdu Meter: A Quick Overview</h3>\n",
      "\n",
      "The meter of Urdu is quantitative and based on syllable length rather than stress. Certain combinations of consonants and vowels form what can be thought as \"long\" (=) or \"short\" (-) syllables, though quite a number of them remain flexible. These are then arranged into particular patterns, described as different types of feet. The focus of this project is a poetic form called the <i>\u0121hazal</i>, which consists of a number of two-line verses all in the same meter and sharing some rhyming elements.\n",
      "\n",
      "The following two-line verse would scan as:\n",
      "\n",
      "    =  -   =  = =   -   =   =   =  -    = =   =  - =\n",
      "    naqsh faryaadii hai kis kii sho;xii-e ta;hriir kaa\n",
      "    =  -  =   =   =  - =   =   =  - =   =   =  - =\n",
      "    kaa;gazii hai pairahan har paikar-e ta.sviir kaa\n",
      "\n",
      "The meter (=-==/=-==/=-==/=-=) consists of three feet in the form =-== followed by one that is =-=.\n",
      "\n",
      "There are different combinations of consonants and vowels that yield the long and short syllables. For example, a consonant followed by a short vowel (a,i,u) followed by consonant can be long (e.g., naq, far, kis, ta;h, han, ta.s). A word-final consonant can be a short (e.g., -sh, -r) as can a consonant followed by a short vowel (e.g., ;ga, ra, ka). A consonant followed by a long vowel at the end of a word can be either long (e.g., dii, kaa, zii), or it can short (hai). There are also a number of exceptional words and combinations."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Computing Urdu Meter</h3>\n",
      "\n",
      "To computer Urdu meter requires a number of steps.\n",
      "\n",
      "1. <b>The input string is tokenized.</b>\n",
      "\n",
      "    The input is broken up into its component parts. Each of the tokens are marked as belonging to a particular class (e.g., 'consonant,' vowel').\n",
      "\n",
      "    <i>Example</i>: \"naqsh\" therefore would be broken up into its components parts: 'n', 'a', 'q', and 'sh'. \n",
      "\n",
      "2. <b>The tokens, in their particular contexts, are parsed to render what category they are.</b>\n",
      "\n",
      "    The primary categories are \"c\" (consonant), \"v\" (long vowel), \"s\" (short vowel), \"b\" (break, e.g. space). A few depend on what tokens proceed or follow them (hence the use of classes above). There are a few additional classes, such as \"al\" for the Arabic al-,il-,ul-, and \"z\" for the Persian enclitic izafat (-e). \n",
      "\n",
      "    <i>Example</i>: The production of \"naqsh faryaadii hai kis kii sho;xii-e ta;hriir kaa\" would be:  csccbclclbclbcscbclbclclzbcscclcbcl (The original tokens are also retained).\n",
      "\n",
      "3. <b>These category strings are parsed and then categorized as long or short, generating an array of metrical possibilities.</b>\n",
      "\n",
      "    This step requires loading another set of rules that define variable patterns for long and short syllables. Then, all possible matches are generated and added to the results, and a meter string is constructed. Unpermitted combinations are (optionally) dropped. All combinations for a particular line can be generated.\n",
      "\n",
      "    <i>Example</i>: The phrase \"naqsh faryaadii,\" categorized as \"csccbcscclcl\" will produce the following scansions \"=-===\" and \"=-==-\". The descriptive matches will be \"l_csc\" [long syllable, consonant-short vowel-consonant],\"s_c\", \"l_csc\", \"l_cl\", and then \"l_clb\" or \"s_clb.\" If the phrase is \"naqsh faryaadii hai\" (csccbcscclclbcl) the possibilities will be \"=-====\",\"=-===-\", \"=-==-=\", and \"=-==--\".\n",
      "\n",
      "4. <b>Generated metrical possibilities are compared to acceptable ones (based on genre), and the final match is determined.</b>\n",
      "\n",
      "    This works for poetry in established genres, such as the ghazal. Detecting meter in more complex "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Technical Details</h3>\n",
      "\n",
      "This project contains two modules (parser.py and scanner.py). It reuses a custom lexer/parser (parser.py) in stages I,II, and III above. The scanner (scanner.py) calls the scanner in I,II,III, and can check against established meters in IV.\n",
      "\n",
      "<h4>Parser/Lexer (parser.py)</h4>\n",
      "\n",
      "parser.py contains a Parser class that can take either a YAML file or direct data. YAML is used here for convenience, as it is easy to read. The parser settings file consists of rules and tokens. The tokens also contain a class:\n",
      "\n",
      "tokens:\n",
      "  this_is_a_token:\n",
      "  - token_class\n",
      "  a:\n",
      "  - short_vowel\n",
      "\n",
      "The rules consist of one or more token, as well as the possibilities of previous token matches, previous class matches, following tokens, and following token classes in the following format. This is a string, followed by a production string. In step II above, the production string would be \"v\" (for vowel), \"s\" for short vowel, etc. Here is an example:\n",
      "\n",
      "rules:\n",
      "   <prev_class> token_a: a_production  # matches a token_a followed by a token of type prev_class\n",
      "   token_b: b_production               # matches a token_b with no restrictions\n",
      "   token_a token_b: ab_production      # matches a token_a followed by a token_b, both are consumed\n",
      "   <prev_class> token_a (token_c):     # token_a followed followed by token_c, preceded by token of of type prev_class\n",
      "   (<prev_class_b> token_a) token_b:   # a token_b preceded by a token_a preceded by a token of type prev_class_b\n",
      "       \n",
      "The parser generates a regular expression for matching of tokens, and it sorts its own rules based on number of conditions and length.\n",
      "       \n",
      "Let's look at an example.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from parser import Parser\n",
      "p = Parser('settings/urdu-meter.yaml') # this is the setting file used in step 1."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The parser has a 'tokenize' function\n",
      "_ = \"naqsh faryaadii hai kis kii sho;xii-e ta;hriir kaa\"\n",
      "print p.tokenize(_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['n', 'a', 'q', 'sh', ' ', 'f', 'a', 'r', 'y', 'aa', 'd', 'ii', ' ', 'h', 'ai', ' ', 'k', 'i', 's', ' ', 'k', 'ii', ' ', 'sh', 'o', ';x', 'ii', '-e', ' ', 't', 'a', ';h', 'r', 'ii', 'r', ' ', 'k', 'aa']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# It also has a 'parse' function that yields a string output\n",
      "# def parse(self,input,on_error='',on_error_additional='',return_all_matches=False, debug=False)\n",
      "p.parse(_)# It also has a \"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "'csccbcsccvcvbcvbcscbcvbcvcv<ii+z>zbcsccvcbcv'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The details of the parse are stored in the Parser object and can be retrieved.\n",
      "# This lets us know what was matched later, e.g. that \"n\" was the first \"c\" (consonant) above.\n",
      "_ = 'naqsh'\n",
      "p.parse(_)\n",
      "print p.parse_details # this is an array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'tokens': ['n'], 'start': 0, 'rule_id': 38, 'rule': {'tokens': ['n'], 'production': 'c'}}, {'tokens': ['a'], 'start': 1, 'rule_id': 87, 'rule': {'tokens': ['a'], 'production': 's'}}, {'tokens': ['q'], 'start': 2, 'rule_id': 95, 'rule': {'tokens': ['q'], 'production': 'c'}}, {'tokens': ['sh'], 'start': 3, 'rule_id': 98, 'rule': {'tokens': ['sh'], 'production': 'c'}}]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Metrical Scanner (scanner.py)</h4>\n",
      "\n",
      "The metrical \"scanner\" uses a number of Parser objects to perform metrical scans. It also handles the pretty output.\n",
      "\n",
      "The file scanner.py contains an object type called Scanner. It can take following parameters, each a YAML file:\n",
      "- a meter_file (used in Step II ** need to come up with a better name)\n",
      "- a short_file (which contains rules for short syllables) and a long_file (for long ones)\n",
      "- a meter_description_file (which gives a more general description of the particular meters)\n",
      "- a meters_file (which has raw possibilities for matches) {derived from the reference_file}\n",
      "\n",
      "The \"meter_file\" is described above.\n",
      "\n",
      "The short_file and the long_file follows the same rules, and look like this:\n",
      "\n",
      "  <v> c c &lt;b>: s_(v)cc(b) # a consonant followed by a consonant preceded by a vowel and followed by a word break \n",
      "                          # it produces a description, s_(v)ccc(b)\n",
      "\n",
      "The meter_description_file contains a title and a short description of the meter, e.g.\n",
      "  G1: =-==/=-==/=-==/=-=(-)\n",
      "\n",
      "The meters_file contains the multiple possibilities for particular meters. The Scanner removes the feet marker (/):\n",
      "  =-==/=-==/=-==/=-=: G1\n",
      "  =-==/=-==/=-==/=-=-: G1\n",
      "\n",
      "Default files are all in the settings directory.\n",
      "      \n",
      "      \n",
      "    The primary function of the scanner is scan. It contains a number of options--to only include known meters and to start debug mode:\n",
      "      \n",
      "       def scan(self, s, known_only=False, debug=False, parser_debug = False):\n",
      "\n",
      "Let's look at an example.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scanner import Scanner\n",
      "s = Scanner()\n",
      "input_string = 'naqsh faryaadii hai kis kii sho;xii-e ta;hriir kaa'\n",
      "scan_results = s.scan(input_string, known_only=True)\n",
      "scan_results.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "['results', 'tkns', 'orig_parse']"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# As you can see, it returns results, original tokens, and the original parse.\n",
      "\n",
      "print \"tkns are:\"\n",
      "print scan_results['tkns'][0:5]  # these are the results from Stage 2 \n",
      "print \"----\"\n",
      "print scan_results['orig_parse'][0:5] # these are the parse_details from Stage 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tkns are:\n",
        "['c', 's', 'c', 'c', 'b']\n",
        "----\n",
        "[{'tokens': ['n'], 'start': 0, 'rule_id': 38, 'rule': {'tokens': ['n'], 'production': 'c'}}, {'tokens': ['a'], 'start': 1, 'rule_id': 87, 'rule': {'tokens': ['a'], 'production': 's'}}, {'tokens': ['q'], 'start': 2, 'rule_id': 95, 'rule': {'tokens': ['q'], 'production': 'c'}}, {'tokens': ['sh'], 'start': 3, 'rule_id': 98, 'rule': {'tokens': ['sh'], 'production': 'c'}}, {'tokens': ' ', 'start': 4, 'rule_id': 32, 'rule': {'tokens': ' ', 'production': 'b'}}]\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# results holds an array of metrical matches.\n",
      "result = scan_results['results'][0]\n",
      "print result.keys()\n",
      "# The keys of each are:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['matches', 'index', 'meter_string', 'scan']\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The results accumlate through the scanning process.\n",
      "# The final results also include:\n",
      "#   the last ['index'] of the string processed\n",
      "#   the ['meter_string'] of the last match\n",
      "#   the results ['scan']\n",
      "#   ['matches'] stores an array of previous matches, with the following information\n",
      "#      meter_string\n",
      "#      rule_id\n",
      "#      start or index\n",
      "#      tokens\n",
      "# \n",
      "# ['scan'] shows the final match:\n",
      "print \"['scan'] is:         \" + result['scan']#'][0:5]\n",
      "print \"['meter_string'] is: \" + result['meter_string']\n",
      "print \"['index'] is:        \" + str(result['index'])\n",
      "print \"['matches'] is:      \"\n",
      "result['matches']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['scan'] is:         =-===-===-===-=\n",
        "['meter_string'] is: =\n",
        "['index'] is:        38\n",
        "['matches'] is:      \n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "[{'meter_string': '=',\n",
        "  'rule': {'production': 'l_csc', 'tokens': ['c', 's', 'c']},\n",
        "  'rule_id': 20,\n",
        "  'start': 0,\n",
        "  'tokens': ['c', 's', 'c']},\n",
        " {'meter_string': '-',\n",
        "  'rule': {'production': 's_c', 'tokens': ['c']},\n",
        "  'rule_id': 47,\n",
        "  'start': 3,\n",
        "  'tokens': ['c']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_csc', 'tokens': ['b', 'c', 's', 'c']},\n",
        "  'rule_id': 17,\n",
        "  'start': 4,\n",
        "  'tokens': ['b', 'c', 's', 'c']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_cv', 'tokens': ['c', 'v']},\n",
        "  'rule_id': 50,\n",
        "  'start': 8,\n",
        "  'tokens': ['c', 'v']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_cv', 'tokens': ['c', 'v']},\n",
        "  'rule_id': 50,\n",
        "  'start': 10,\n",
        "  'tokens': ['c', 'v']},\n",
        " {'meter_string': '-',\n",
        "  'rule': {'next_class': 'b',\n",
        "   'production': 's_bcv(b)',\n",
        "   'tokens': ['b', 'c', 'v']},\n",
        "  'rule_id': 4,\n",
        "  'start': 12,\n",
        "  'tokens': ['b', 'c', 'v']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_csc', 'tokens': ['b', 'c', 's', 'c']},\n",
        "  'rule_id': 17,\n",
        "  'start': 15,\n",
        "  'tokens': ['b', 'c', 's', 'c']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_bcv', 'tokens': ['b', 'c', 'v']},\n",
        "  'rule_id': 31,\n",
        "  'start': 19,\n",
        "  'tokens': ['b', 'c', 'v']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_bcv', 'tokens': ['b', 'c', 'v']},\n",
        "  'rule_id': 31,\n",
        "  'start': 22,\n",
        "  'tokens': ['b', 'c', 'v']},\n",
        " {'meter_string': '-',\n",
        "  'rule': {'production': 's_c', 'tokens': ['c']},\n",
        "  'rule_id': 47,\n",
        "  'start': 25,\n",
        "  'tokens': ['c']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_v<ii+z>z', 'tokens': ['v<ii+z>', 'z']},\n",
        "  'rule_id': 40,\n",
        "  'start': 26,\n",
        "  'tokens': ['v<ii+z>', 'z']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_csc', 'tokens': ['b', 'c', 's', 'c']},\n",
        "  'rule_id': 17,\n",
        "  'start': 28,\n",
        "  'tokens': ['b', 'c', 's', 'c']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_cv', 'tokens': ['c', 'v']},\n",
        "  'rule_id': 50,\n",
        "  'start': 32,\n",
        "  'tokens': ['c', 'v']},\n",
        " {'meter_string': '-',\n",
        "  'rule': {'production': 's_c', 'tokens': ['c']},\n",
        "  'rule_id': 47,\n",
        "  'start': 34,\n",
        "  'tokens': ['c']},\n",
        " {'meter_string': '=',\n",
        "  'rule': {'production': 'l_bcv', 'tokens': ['b', 'c', 'v']},\n",
        "  'rule_id': 31,\n",
        "  'start': 35,\n",
        "  'tokens': ['b', 'c', 'v']}]"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If we scan with known_only set to False, it shows other metrical combinations\n",
      "\n",
      "scan_results = s.scan(input_string, known_only=False)\n",
      "print \"for the input '\"+input_string+\"' there are \"+str(len(scan_results['results']))+\" results:\"\n",
      "for r in scan_results['results']: print '  '+r['scan']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "for the input 'naqsh faryaadii hai kis kii sho;xii-e ta;hriir kaa' there are 96 results:\n",
        "  =-===========--\n",
        "  =-===========-=\n",
        "  =-========-==--\n",
        "  =-========-==-=\n",
        "  =-=======-===--\n",
        "  =-=======-===-=\n",
        "  =-=======--==--\n",
        "  =-=======--==-=\n",
        "  =-=======-===--\n",
        "  =-=======-===-=\n",
        "  =-=======--==--\n",
        "  =-=======--==-=\n",
        "  =-=====-=====--\n",
        "  =-=====-=====-=\n",
        "  =-=====-==-==--\n",
        "  =-=====-==-==-=\n",
        "  =-=====-=-===--\n",
        "  =-=====-=-===-=\n",
        "  =-=====-=--==--\n",
        "  =-=====-=--==-=\n",
        "  =-=====-=-===--\n",
        "  =-=====-=-===-=\n",
        "  =-=====-=--==--\n",
        "  =-=====-=--==-=\n",
        "  =-===-=======--\n",
        "  =-===-=======-=\n",
        "  =-===-====-==--\n",
        "  =-===-====-==-=\n",
        "  =-===-===-===--\n",
        "  =-===-===-===-=\n",
        "  =-===-===--==--\n",
        "  =-===-===--==-=\n",
        "  =-===-===-===--\n",
        "  =-===-===-===-=\n",
        "  =-===-===--==--\n",
        "  =-===-===--==-=\n",
        "  =-===-=-=====--\n",
        "  =-===-=-=====-=\n",
        "  =-===-=-==-==--\n",
        "  =-===-=-==-==-=\n",
        "  =-===-=-=-===--\n",
        "  =-===-=-=-===-=\n",
        "  =-===-=-=--==--\n",
        "  =-===-=-=--==-=\n",
        "  =-===-=-=-===--\n",
        "  =-===-=-=-===-=\n",
        "  =-===-=-=--==--\n",
        "  =-===-=-=--==-=\n",
        "  =-==-========--\n",
        "  =-==-========-=\n",
        "  =-==-=====-==--\n",
        "  =-==-=====-==-=\n",
        "  =-==-====-===--\n",
        "  =-==-====-===-=\n",
        "  =-==-====--==--\n",
        "  =-==-====--==-=\n",
        "  =-==-====-===--\n",
        "  =-==-====-===-=\n",
        "  =-==-====--==--\n",
        "  =-==-====--==-=\n",
        "  =-==-==-=====--\n",
        "  =-==-==-=====-=\n",
        "  =-==-==-==-==--\n",
        "  =-==-==-==-==-=\n",
        "  =-==-==-=-===--\n",
        "  =-==-==-=-===-=\n",
        "  =-==-==-=--==--\n",
        "  =-==-==-=--==-=\n",
        "  =-==-==-=-===--\n",
        "  =-==-==-=-===-=\n",
        "  =-==-==-=--==--\n",
        "  =-==-==-=--==-=\n",
        "  =-==--=======--\n",
        "  =-==--=======-=\n",
        "  =-==--====-==--\n",
        "  =-==--====-==-=\n",
        "  =-==--===-===--\n",
        "  =-==--===-===-=\n",
        "  =-==--===--==--\n",
        "  =-==--===--==-=\n",
        "  =-==--===-===--\n",
        "  =-==--===-===-=\n",
        "  =-==--===--==--\n",
        "  =-==--===--==-=\n",
        "  =-==--=-=====--\n",
        "  =-==--=-=====-=\n",
        "  =-==--=-==-==--\n",
        "  =-==--=-==-==-=\n",
        "  =-==--=-=-===--\n",
        "  =-==--=-=-===-=\n",
        "  =-==--=-=--==--\n",
        "  =-==--=-=--==-=\n",
        "  =-==--=-=-===--\n",
        "  =-==--=-=-===-=\n",
        "  =-==--=-=--==--\n",
        "  =-==--=-=--==-=\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}